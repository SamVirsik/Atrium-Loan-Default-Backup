{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e15c1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdcd01b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\samvi\\AppData\\Local\\Temp\\ipykernel_15640\\2712093529.py:1: DtypeWarning: Columns (16,23,30,33,36,37,38,39,40,41,42,43,44,50,53,55,58,59,60,65) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(r'C:\\Users\\samvi\\Documents\\Coding Projects\\Embedded Work\\Data_Used\\Training_Data.csv')\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(r'C:\\Users\\samvi\\Documents\\Coding Projects\\Embedded Work\\Data_Used\\Training_Data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05758c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "MSAs = pd.read_csv(r'C:\\Users\\samvi\\Documents\\Coding Projects\\Embedded Work\\Data_Used\\MSA Master Sheet.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aeb1ffe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSA Code</th>\n",
       "      <th>MSA Name</th>\n",
       "      <th>FIPS State Code</th>\n",
       "      <th>HPI Volatility</th>\n",
       "      <th>Most Recent HPI</th>\n",
       "      <th>Population</th>\n",
       "      <th>Unemployment Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10180</td>\n",
       "      <td>Abilene, TX</td>\n",
       "      <td>48</td>\n",
       "      <td>6.376873</td>\n",
       "      <td>336.73</td>\n",
       "      <td>184278</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10380</td>\n",
       "      <td>Aguadilla, PR</td>\n",
       "      <td>72</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>250.00</td>\n",
       "      <td>250969</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10420</td>\n",
       "      <td>Akron, OH</td>\n",
       "      <td>39</td>\n",
       "      <td>4.253307</td>\n",
       "      <td>257.62</td>\n",
       "      <td>702209</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10500</td>\n",
       "      <td>Albany, GA</td>\n",
       "      <td>13</td>\n",
       "      <td>4.271005</td>\n",
       "      <td>241.76</td>\n",
       "      <td>145451</td>\n",
       "      <td>4.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10540</td>\n",
       "      <td>Albany, OR</td>\n",
       "      <td>41</td>\n",
       "      <td>5.997320</td>\n",
       "      <td>420.17</td>\n",
       "      <td>132474</td>\n",
       "      <td>4.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSA Code       MSA Name  FIPS State Code  HPI Volatility  Most Recent HPI  \\\n",
       "0     10180    Abilene, TX               48        6.376873           336.73   \n",
       "1     10380  Aguadilla, PR               72        6.500000           250.00   \n",
       "2     10420      Akron, OH               39        4.253307           257.62   \n",
       "3     10500     Albany, GA               13        4.271005           241.76   \n",
       "4     10540     Albany, OR               41        5.997320           420.17   \n",
       "\n",
       "   Population  Unemployment Rate  \n",
       "0      184278                3.5  \n",
       "1      250969                7.6  \n",
       "2      702209                4.4  \n",
       "3      145451                4.2  \n",
       "4      132474                4.6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSAs.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09f1d136",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_msa(msa):\n",
    "    msa = str(msa).strip().upper()\n",
    "\n",
    "    if \"METROPOLITAN STATISTICAL AREA\" not in msa:\n",
    "        return msa.title()\n",
    "\n",
    "    # Remove suffix\n",
    "    msa = msa.replace(\" METROPOLITAN STATISTICAL AREA\", \"\")\n",
    "\n",
    "    # Check for comma to separate city and state\n",
    "    if ',' in msa:\n",
    "        city_part, state_part = msa.rsplit(',', 1)\n",
    "        # Replace hyphens in both parts with spaces\n",
    "        city_clean = re.sub(r'-+', ' ', city_part.strip()).title()\n",
    "        state_clean = re.sub(r'-+', ' ', state_part.strip()).upper()\n",
    "        return f\"{city_clean}, {state_clean}\"\n",
    "    else:\n",
    "        # Fallback\n",
    "        return re.sub(r'-+', ' ', msa).title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "325fe4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['MSA_clean'] = df['Metropolitan Statistical Area'].apply(clean_msa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e002e4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "msa_corrections = {\n",
    "    'Aguadilla Isabela, PR': 'Aguadilla, PR',\n",
    "    'Albany Lebanon, OR': 'Albany, OR',\n",
    "    'Atlanta Sandy Springs Alpharetta, GA': 'Atlanta Sandy Springs Roswell, GA', #Not perfect\n",
    "    'Austin Round Rock Georgetown, TX': 'Austin Round Rock San Marcos, TX', #Not perfect\n",
    "    'Bakersfield, CA': 'Bakersfield Delano, CA',\n",
    "    'Birmingham Hoover, AL': 'Birmingham, AL',\n",
    "    'Blacksburg Christiansburg, VA': 'Blacksburg Christiansburg Radford, VA',\n",
    "    'Bloomsburg Berwick, PA': 'Scranton  Wilkes Barre, PA', #GPT beleives this is closest\n",
    "    'Bridgeport Stamford Norwalk, CT': 'Bridgeport Stamford Danbury, CT', \n",
    "    'Brunswick, GA': 'Brunswick St. Simons, GA', \n",
    "    'California Lexington Park, MD': 'Lexington Park, MD', \n",
    "    'Carbondale Marion, IL': 'Cape Girardeau, MO IL', #GPT Believes this is closest\n",
    "    'Chambersburg Waynesboro, PA': 'Chambersburg, PA',\n",
    "    'Chicago Naperville Elgin, IL IN WI': 'Chicago Naperville Elgin, IL IN',\n",
    "    'Cleveland Elyria, OH': 'Cleveland, OH',\n",
    "    \"Coeur D'Alene, ID\": \"Coeur d'Alene, ID\",\n",
    "    'Cumberland, MD WV': 'Hagerstown Martinsburg, MD WV', #GPT\n",
    "    'Danville, IL': 'Champaign Urbana, IL', #GPT\n",
    "    'Dayton Kettering, OH': 'Dayton Kettering Beavercreek, OH',\n",
    "    'Denver Aurora Lakewood, CO': 'Denver Aurora Centennial, CO',\n",
    "    'East Stroudsburg, PA': 'Allentown Bethlehem Easton, PA NJ', #GPT\n",
    "    'Elizabethtown Fort Knox, KY': 'Elizabethtown, KY',\n",
    "    'Evansville, IN KY': 'Evansville, IN',\n",
    "    'Fairbanks, AK': 'Fairbanks College, AK',\n",
    "    'Fond Du Lac, WI': 'Fond du Lac, WI',\n",
    "    'Fort Collins, CO': 'Fort Collins Loveland, CO',\n",
    "    'Grand Rapids Kentwood, MI': 'Grand Rapids Wyoming Kentwood, MI',\n",
    "    'Greenville Anderson, SC': 'Greenville Anderson Greer, SC',\n",
    "    'Hartford East Hartford Middletown, CT': 'Hartford West Hartford East Hartford, CT',\n",
    "    'Hilton Head Island Bluffton, SC': 'Hilton Head Island Bluffton Port Royal, SC',\n",
    "    'Houma Thibodaux, LA': 'Houma Bayou Cane Thibodaux, LA',\n",
    "    'Houston The Woodlands Sugar Land, TX': 'Houston Pasadena The Woodlands, TX',\n",
    "    'Indianapolis Carmel Anderson, IN': 'Indianapolis Carmel Greenwood, IN',\n",
    "    'Joplin, MO': 'Joplin, MO KS',\n",
    "    'Kahului Wailuku Lahaina, HI': 'Kahului Wailuku, HI',\n",
    "    'Las Vegas Henderson Paradise, NV': 'Las Vegas Henderson North Las Vegas, NV',\n",
    "    'Longview, WA': 'Longview Kelso, WA',\n",
    "    'Madera, CA': 'Fresno, CA', #GPT\n",
    "    'Mcallen Edinburg Mission, TX': 'McAllen Edinburg Mission, TX',\n",
    "    'Miami Fort Lauderdale Pompano Beach, FL': 'Miami Fort Lauderdale West Palm Beach, FL', \n",
    "    'Multiple Properties': 'Multiple Properties', #STILL AN ISSUE\n",
    "    'Muskegon, MI': 'Muskegon Norton Shores, MI',\n",
    "    'Myrtle Beach Conway North Myrtle Beach, SC NC': 'Myrtle Beach Conway North Myrtle Beach, SC',\n",
    "    'Nashville Davidson Murfreesboro Franklin, TN': 'Nashville Davidson  Murfreesboro  Franklin, TN',\n",
    "    'New Bern, NC': 'Greenville, NC', #GPT\n",
    "    'New Haven Milford, CT': 'New Haven, CT',\n",
    "    'New York Newark Jersey City, NY NJ PA': 'New York Newark Jersey City, NY NJ',\n",
    "    'Non Msa': 'Non Msa', #STILL AN ISSUE\n",
    "    'North Port Sarasota Bradenton, FL': 'North Port Bradenton Sarasota, FL',\n",
    "    'Norwich New London, CT': 'Norwich New London Willimantic, CT',\n",
    "    'Ocean City, NJ': 'Atlantic City Hammonton, NJ', #GPT\n",
    "    'Ogden Clearfield, UT': 'Ogden, UT',\n",
    "    'Omaha Council Bluffs, NE IA': 'Omaha, NE IA',\n",
    "    'Panama City, FL': 'Panama City Panama City Beach, FL',\n",
    "    'Pine Bluff, AR': 'Little Rock North Little Rock Conway, AR', #GPT\n",
    "    'Poughkeepsie Newburgh Middletown, NY': 'Kiryas Joel Poughkeepsie Newburgh, NY', \n",
    "    'Provo Orem, UT': 'Provo Orem Lehi, UT',\n",
    "    'Racine, WI': 'Racine Mount Pleasant, WI',\n",
    "    'Salisbury, MD DE': 'Salisbury, MD',\n",
    "    'Salt Lake City, UT': 'Salt Lake City Murray, UT',\n",
    "    'San Francisco Oakland Berkeley, CA': 'San Francisco Oakland Fremont, CA',\n",
    "    'San German, PR': 'Mayagüez, PR', #GPT\n",
    "    'San Juan Bayamon Caguas, PR': 'San Juan Bayamón Caguas, PR',\n",
    "    'Scranton Wilkes Barre, PA': 'Scranton  Wilkes Barre, PA', \n",
    "    'Sebastian Vero Beach, FL': 'Sebastian Vero Beach West Vero Corridor, FL',\n",
    "    'Sebring Avon Park, FL': 'Sebring, FL',\n",
    "    'Sioux Falls, SD': 'Sioux Falls, SD MN',\n",
    "    'Staunton, VA': 'Staunton Stuarts Draft, VA',\n",
    "    'Stockton, CA': 'Stockton Lodi, CA',\n",
    "    'The Villages, FL': 'Wildwood The Villages, FL',\n",
    "    'Vineland Bridgeton, NJ': 'Vineland, NJ',\n",
    "    'Virginia Beach Norfolk Newport News, VA NC': 'Virginia Beach Chesapeake Norfolk, VA NC',\n",
    "    'Wausau Weston, WI': 'Wausau, WI',\n",
    "    'Wenatchee, WA': 'Wenatchee East Wenatchee, WA',\n",
    "    'Worcester, MA CT': 'Worcester, MA',\n",
    "    'Youngstown Warren Boardman, OH PA': 'Youngstown Warren, OH'\n",
    "}\n",
    "\n",
    "df['MSA_clean'] = df['MSA_clean'].replace(msa_corrections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94a0840a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique in df1: 380\n",
      "Total unique in df2: 393\n",
      "Number of exact matches: 378\n",
      "Number of values only in df1: 2\n",
      "Number of values only in df2: 15\n"
     ]
    }
   ],
   "source": [
    "# Drop NA and get unique values\n",
    "set1 = set(df['MSA_clean'].dropna().unique())\n",
    "set2 = set(MSAs['MSA Name'].dropna().unique())\n",
    "\n",
    "# Exact matches\n",
    "overlap = set1 & set2\n",
    "\n",
    "# Unique elements in each\n",
    "only_in_df1 = set1 - set2\n",
    "only_in_df2 = set2 - set1\n",
    "\n",
    "print(f\"Total unique in df1: {len(set1)}\")\n",
    "print(f\"Total unique in df2: {len(set2)}\")\n",
    "print(f\"Number of exact matches: {len(overlap)}\")\n",
    "print(f\"Number of values only in df1: {len(only_in_df1)}\")\n",
    "print(f\"Number of values only in df2: {len(only_in_df2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e886d450",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Only in df1                       Only in df2\n",
      "0   Multiple Properties      Amherst Town Northampton, MA\n",
      "1               Non Msa                       Arecibo, PR\n",
      "2                                             Bozeman, MT\n",
      "3                                          Eagle Pass, TX\n",
      "4                                             Guayama, PR\n",
      "5                                              Helena, MT\n",
      "6                                             Kenosha, WI\n",
      "7                                               Minot, ND\n",
      "8                                          Paducah, KY IL\n",
      "9                            Pinehurst Southern Pines, NC\n",
      "10                                              Ponce, PR\n",
      "11                                           Sandusky, OH\n",
      "12                       Slidell Mandeville Covington, LA\n",
      "13                                      Traverse City, MI\n",
      "14                                  Waterbury Shelton, CT\n"
     ]
    }
   ],
   "source": [
    "list1 = sorted(only_in_df1)\n",
    "list2 = sorted(only_in_df2)\n",
    "\n",
    "# Pad the shorter list so lengths match\n",
    "max_len = max(len(list1), len(list2))\n",
    "list1 += [\"\"] * (max_len - len(list1))\n",
    "list2 += [\"\"] * (max_len - len(list2))\n",
    "\n",
    "mismatch_df = pd.DataFrame({\n",
    "    \"Only in df1\": list1,\n",
    "    \"Only in df2\": list2\n",
    "})\n",
    "\n",
    "# View or save\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.width', 200)       # Make console wider\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "print(mismatch_df)\n",
    "# mismatch_df.to_csv(\"msa_mismatches.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
